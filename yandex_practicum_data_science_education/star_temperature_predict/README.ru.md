**RU** | [EN](README.md)

# Прогнозирование температуры звезды

- [Посмотреть Jupyter-блокнот](star_temperature_predict_ru.ipynb)

Стэк: `numpy`, `pandas`, `matplotlib`, `seaborn`, `torch`, `Sequential`, `Adamax`, `Linear`, `ReLU`, `Dropout`, `BatchNorm1d`, `math`, `itertools`, `OneHotEncoder`, `StandardScaler`, ml алгоритмы

## Описание

- Заказчик, обсерватория «Небо на ладони»
- Придумать, как с помощью нейросети определять абсолютную температуру на поверхности обнаруженных звёзд. Улучшить точность предсказания температуры звёзд машинным обучением вместо других методов
- Обычно использовались следующие методы (каждый из них имеет плюсы и минусы)
    - Закон смещения Вина
    - Закон Стефана-Больцмана
    - Спектральный анализ
- В базе обсерватории есть характеристики уже изученных 240 звёзд
- Метрика RMSE должна быть менее 4500
- Сделать Baseline и улушченную версию нейронной сети у которой оставить: количество слоёв, нейронов, вид функции активации — оставьте как в Baseline, чтобы сравнить результат

## Выводы

**Анализ данных**

- В датасете всго лишь 240 наблюдений
- Температура звёзд находится в диапазоне от 1939 до 40000 по Кельвину, медиана 5776 градусов
- Светимость звезды относительно Солнца от 0.00008 до 849420, медиана 0.0705
- Радиус относительно Солнца от 0.0084 до 1948.5, медиана 0.7625
- Абсолютная звёздная величина от -11.92 до 20.06, где чаще всего встречаются значения -7 и 13, а меньше всего 8
- Количество звёзд каждого типа по 40, всего 6 типов

**Результаты базовой модели**

- Функция оптимизации `Adamax` лучше чем `Adam`
- Изменение предварительной инициализации весов под имеющееся распределение не всегда способствует лучшему обучению
- Под конкретную задачу не удалось получить хорошее предсказание используя только 1 скрытый слой
- Для задачи регрессии в последнем слое лучше использовать не функцию активации, а линейную
- Иногда при одних и тех же плохих гиперпараметрах сеть перестаёт хорошо обучаться, может выдать хорошую метрику, а затем плохую, т.е. плохая стабильность модели
- В целом нужно много экспериментов и опыт для успешного подбора гиперпарметров: архитектура_сети, скорость обучения, количество эпох, размер батча, предварительная инициализация
- Лучшая метрика на валидационной выборке была **RMSE 6371.9111**
- Метрика на тестовой выборке **12146.8710**

**Результаты улучшенной модели**

- На экспериментах по улучшению модели было сделано предположение, что есть проблема в данных по тому что все возможные технихи были применены, но метрика оставалась низкой. Проблема оказалась в признаке цвета звёзд
- Сильно улучшила метрику замена функции активации с `Tanh` на `ReLU`
- Хорошего эффекта Batch Normalization не видно, если плохая функция активации
- Модель работает чуть хуже лучше с Dropout в среднем с разницей 283 RMSE
- Модель работает значительно лучше с Batch Normalization в среднем с разницей 1165 RMSE
- Лучшей модели при переборе удалось достичь при **RMSE 2540** на валидационной выборке и таких параметрах
    - `learning_rate = 0.1`
    - `num_epochs = 300`
    - `dropout = False`
    - `batch_norm = True`
- Метрика на тестовой выборке **RMSE 4230**