**RU** | [EN](README.md)

# Определение токсичных комментариев с BERT

- [Посмотреть Jupyter-блокнот](toxic_comments_detection_ru.ipynb)

Стэк: `transformers`, `torch`, `sklearn`, `pandas`, `tqdm`, BERT, NLP

## Описание

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества *F1* не меньше 0.75. 

**Инструкция по выполнению проекта**

1. Загрузите и подготовьте данные.
2. Обучите разные модели. 
3. Сделайте выводы.

Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.

## Выводы

- Были сделаны 2 разные предобработки текста для 2 разных моделей машинного обучения в эмбеддинги для LogisticRegression и токены для BERT
- Модели были обучены для определения токсичности и не токсичности текста
- На валидации были получены следующие результаты метрики F1:
  - LR 0.554869
  - BERT 0.861111
- Лучшей моделью оказалась BERT с метрикой **F1 0.86** на кросс-валидации и **F1 0.80** на тестовой выборке